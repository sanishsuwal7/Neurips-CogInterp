{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51e5dd0b-fe08-46ab-80c8-eca413ece8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1f4b570-dee5-4273-8607-18464c58ee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nonzeros(model):\n",
    "    \"\"\"\n",
    "    This function inspects every parameter tensor in the given model and\n",
    "    counts how many elements are non-zero vs. zero.\n",
    "\n",
    "    Parameters:\n",
    "        model : The model whose parameters will be analyzed.\n",
    "\n",
    "    Returns:\n",
    "        float : The percentage of non-zero parameters in the model.\n",
    "    \"\"\"\n",
    "    non_zeros = 0\n",
    "    total_parameters = 0\n",
    "    # Iterate over each parameter in the model\n",
    "    for name, param in model.named_parameters():\n",
    "        # Convert parameter to a NumPy array on CPU\n",
    "        tensor = param.data.cpu().numpy()\n",
    "        tensor_shape = tensor.shape\n",
    "\n",
    "        # Count how many values are non-zero in this tensor\n",
    "        non_zero_count = np.count_nonzero(tensor)\n",
    "        \n",
    "        # Calculate total number of parameters in this tensor\n",
    "        parameters = np.prod(tensor_shape)\n",
    "        non_zeros += non_zero_count\n",
    "        total_parameters += parameters\n",
    "        \n",
    "    print(f'Non pruned: {non_zeros}, pruned : {total_parameters - non_zeros}, total: {total_parameters}, Compression rate:{100 * (total_parameters-non_zeros) / total_parameters:6.2f}% pruned')\n",
    "    # percentage of non zero parameters\n",
    "    result = round((non_zeros/total_parameters)*100,1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c616eaf6-daed-44be-9399-d1d78e11fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_initialization(mask_temp, model, initial_state_dict):\n",
    "    \"\"\"\n",
    "    Restore a pruned model's parameters to their original (pre-pruning) values\n",
    "    while keeping the same pruning structure.\n",
    "\n",
    "    Parameters:\n",
    "        mask_temp : Binary masks for each weight tensor (1 = keep, 0 = pruned).\n",
    "        model : The model to restore.\n",
    "        initial_state_dict : A state_dict containing the original parameters before pruning.\n",
    "    \"\"\"\n",
    "    step = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        # restore bias fully\n",
    "        if \"bias\" in name:\n",
    "            param.data = initial_state_dict[name]\n",
    "            \n",
    "        # restore weights with mask applied\n",
    "        if \"weight\" in name: \n",
    "            weight_device = param.device\n",
    "            \n",
    "            # Multiply original weights by mask to keep pruned positions at zero\n",
    "            masked_weights = mask_temp[step] * initial_state_dict[name].cpu().numpy()\n",
    "            param.data = torch.from_numpy(masked_weights).to(weight_device)\n",
    "            step += 1\n",
    "    step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61ced889-87b5-40a3-8290-246752630f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkdir(directory):\n",
    "    \"\"\"\n",
    "    Ensure that a given directory exists. If it does not exist, create it.\n",
    "\n",
    "    Parameters:\n",
    "        directory : Path to the directory to check/create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "305136a0-d55a-4f9d-a823-6dafd998743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_network(percent,mask, model,**kwargs):\n",
    "    \"\"\"\n",
    "    Prune weights in a model by a given percentile of their magnitude.\n",
    "\n",
    "    Parameters:\n",
    "        percent : Percentile value (0â€“100) used as the cutoff for pruning.\n",
    "        mask : List of binary masks (1 = keep, 0 = prune) for each weight tensor.\n",
    "        model : The model whose weights will be pruned.\n",
    "        **kwargs : Additional arguments (currently unused).\n",
    "\n",
    "    Returns:\n",
    "        The updated pruning masks after applying percentile-based pruning.\n",
    "    \"\"\"\n",
    "    global step\n",
    "    # Calculate percentile\n",
    "    step = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        # Not pruning bias term\n",
    "        if 'weight' in name:\n",
    "            tensor = param.data.cpu().numpy()\n",
    "            # Get non-zero weight values\n",
    "            nonzero_values = np.nonzero(tensor)\n",
    "            \n",
    "            # flattened array of nonzero values\n",
    "            nonzero_list = tensor[nonzero_values]\n",
    "            \n",
    "            # Determine magnitude threshold for pruning\n",
    "            percentile_threshold = np.percentile(abs(nonzero_list), percent)\n",
    "\n",
    "            # Convert Tensors to numpy and calculate\n",
    "            weight_device = param.device\n",
    "            \n",
    "            # Create new mask: prune if abs(weight) < threshold, otherwise keep old mask value\n",
    "            new_mask = np.where(abs(tensor) < percentile_threshold, 0, mask[step])\n",
    "            \n",
    "            # Apply new weight and mask\n",
    "            param.data = torch.from_numpy(tensor * new_mask).to(weight_device)\n",
    "            mask[step] = new_mask\n",
    "            step += 1\n",
    "    step = 0\n",
    "    return mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d668792-6645-4ea4-936a-007fb3f940e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask(model):\n",
    "    \"\"\"\n",
    "    Creates a list of masks for the weight parameters of a given model.\n",
    "\n",
    "    Args:\n",
    "        model: The neural network model\n",
    "\n",
    "    Returns:\n",
    "        list: A list of NumPy arrays, where each array is a mask of ones\n",
    "              corresponding to a weight layer in the model.\n",
    "    \"\"\"\n",
    "    global step\n",
    "    step = 0\n",
    "    # Iterate through all named parameters \n",
    "    for name, param in model.named_parameters(): \n",
    "        # Check if the parameter's name contains 'weight'.\n",
    "        if 'weight' in name:\n",
    "            step += 1\n",
    "    # Create a list initialized with 'None', with a length equal to the number of weight layers.\n",
    "    mask = [None]* step \n",
    "    step = 0\n",
    "    for name, param in model.named_parameters(): \n",
    "        if 'weight' in name:\n",
    "            tensor = param.data.cpu().numpy()\n",
    "            # Create a NumPy array of ones with the same shape and type as the weight tensor.\n",
    "            mask[step] = np.ones_like(tensor)\n",
    "            step += 1\n",
    "    step = 0\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "616151f0-2620-4f22-9793-343e4f4fa4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, optimizer, criterion,scheduler):\n",
    "    \"\"\"\n",
    "    Performs one full training epoch for the given model.\n",
    "\n",
    "    Args:\n",
    "        model: The neural network model to be trained.\n",
    "        train_dataloader: The dataloader for the training set.\n",
    "        optimizer: The optimization algorithm.\n",
    "        criterion: The loss function.\n",
    "        scheduler: The learning rate scheduler.\n",
    "\n",
    "    Returns:\n",
    "        float: The loss value from the last batch of the epoch.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.train()\n",
    "    for index, (x_batch, y_batch) in enumerate(train_dataloader):\n",
    "        # Clear previous gradients\n",
    "        optimizer.zero_grad()\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        # Compute predicted outputs by passing inputs to the model.\n",
    "        output = model(x_batch)\n",
    "        # Calculate the loss\n",
    "        loss = criterion(output, y_batch)\n",
    "        # Compute gradient of the loss with respect to model parameters.\n",
    "        loss.backward()\n",
    "        # Update weights: call the optimizer to update the model's weights.\n",
    "        optimizer.step()\n",
    "    # update the learning rate.\n",
    "    scheduler.step()\n",
    "    return loss.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79985cf9-bdba-469e-a109-5bba79fc7470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_dataloader, criterion):\n",
    "    \"\"\"\n",
    "    Evaluates the model's performance on the test dataset.\n",
    "\n",
    "    Args:\n",
    "        model: The trained neural network model to evaluate.\n",
    "        test_dataloader: The dataloader for the test set.\n",
    "        criterion: The loss function used to measure the model's error.\n",
    "\n",
    "    Returns:\n",
    "        float: The classification accuracy of the model on the test set.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_dataloader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            output = model(x_batch)\n",
    "            # Calculate and accumulate loss for the batch.\n",
    "            loss += criterion(output, y_batch).item()\n",
    "            \n",
    "            # Get the predicted class.\n",
    "            pred = output.argmax(1, keepdim=True)\n",
    "            \n",
    "            # Count correct predictions.\n",
    "            correct += pred.eq(y_batch.data.view_as(pred)).sum().item()\n",
    "        loss /= len(test_dataloader.dataset)\n",
    "        accuracy = 100. * correct / len(test_dataloader.dataset)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7aa4b60-e278-4092-a49c-31142309a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_explanation(index, x_batch, y_batch, a_batch_saliency, a_batch_integrad, file_name):\n",
    "    \"\"\"\n",
    "    Visualize and save explanation maps for a single image using ResNet or VGG.\n",
    "\n",
    "    Args:\n",
    "        index : Index of the image in the batch.\n",
    "        x_batch: Batch of input images.\n",
    "        y_batch: labels for the input images.\n",
    "        a_batch_saliency:Explanation maps generated using Integrated Gradients Vanilla Gradient.\n",
    "        a_batch_integrad : Explanation maps generated using Integrated Gradients.\n",
    "        a_batch_smoothgrad: Explanation maps generated using SmoothGrad.\n",
    "        file_name: Name for the file to save the visualizations.\n",
    "    \"\"\"\n",
    "    nr_images = 2\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(nr_images*4, int(nr_images)))\n",
    "    \n",
    "    # Get the raw image data\n",
    "    normal_image = np.moveaxis(x_batch[index], 0, -1) \n",
    "    # Rescale it to the [0, 1] range for display\n",
    "    normal_image_display = (normal_image - normal_image.min()) / (normal_image.max() - normal_image.min())\n",
    "   \n",
    "\n",
    "    #plot normal\n",
    "    axes[0].imshow(normal_image_display)\n",
    "    axes[0].title.set_text(f\"Normal Image {y_batch[index].item()}\")\n",
    "    axes[0].axis(\"off\")\n",
    "    axes[1].imshow(a_batch_saliency[index], cmap=\"hot\")\n",
    "    axes[1].title.set_text(f\"Vanilla Gradient\")\n",
    "    axes[1].axis(\"off\")  \n",
    "    axes[2].imshow(a_batch_integrad[index], cmap=\"hot\")\n",
    "    axes[2].title.set_text(f\"Integrated Gradients\")\n",
    "    axes[2].axis(\"off\")\n",
    "    # axes[3].imshow(a_batch_smoothgrad[index], cmap=\"hot\")\n",
    "    # axes[3].title.set_text(f\"SmoothGrad\")\n",
    "    # axes[3].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(f'explanations/{file_name}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e1c8ee-f16e-4667-98f0-d431126e9cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9eaf602-9ad2-414b-88bb-fad7f7f87ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
